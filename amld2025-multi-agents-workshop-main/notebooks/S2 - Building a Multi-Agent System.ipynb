{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Multi-Agent System with LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the second part of our workshop! Now that we've learned the basics of LangChain and RAG, we'll explore how to build more sophisticated AI applications using **LangGraph**. We'll create a multi-agent system where different AI agents collaborate to provide comprehensive financial analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Our Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like in our previous session, we need to set up our environment with the necessary imports and configurations. We'll use the same OpenAI models and Bloomberg news database, but we'll add some new components for our multi-agent system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\"Please set OPENAI_API_KEY environment variable\")\n",
    "\n",
    "LLM_MODEL = \"gpt-4o-mini\"\n",
    "LLM_TEMPERATURE = 0\n",
    "\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "RETRIEVAL_K = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ChatOpenAI(model=LLM_MODEL, temperature=LLM_TEMPERATURE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vector Store and Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents(pickle_filepath: str) -> list[Document]:\n",
    "    \"\"\"Load documents from a pickle file.\"\"\"\n",
    "    with open(pickle_filepath, \"rb\") as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "\n",
    "def initialize_vector_store(document_chunks: list[Document]) -> Chroma:\n",
    "    \"\"\"Reset the Chroma collection and initialize a vector store using document chunks.\"\"\"\n",
    "    Chroma().reset_collection()\n",
    "    embedding_model = OpenAIEmbeddings(model=EMBEDDING_MODEL)\n",
    "    return Chroma.from_documents(documents=document_chunks, embedding=embedding_model)\n",
    "\n",
    "\n",
    "data_dir = \"../data/\"\n",
    "data_file = \"bloomberg_financial_news_1k.pkl\"\n",
    "\n",
    "documents = load_documents(os.path.join(data_dir, data_file))\n",
    "\n",
    "vector_store = initialize_vector_store(documents)\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": RETRIEVAL_K})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def retrieval(retrieval_query: str) -> list[Document]:\n",
    "    \"\"\"Retrieve documents based on a query.\"\"\"\n",
    "    return retriever.invoke(retrieval_query)\n",
    "\n",
    "\n",
    "tools = [retrieval]\n",
    "tools_by_name = {tool.name: tool for tool in tools}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Multi-Agent Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our system consists of three specialized agents working together:\n",
    "1. **Client Interface Agent (CIA)**: Analyzes client requests and plans research tasks\n",
    "2. **Bloomberg Research Agent (BRA)**: Conducts specific research using the Bloomberg news database\n",
    "3. **Research Synthesis Agent (RSA)**: Synthesizes research into final recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build our workflow with **LangGraph**, we need to implements functions that receive the current state and return state updates. These functions represent the nodes of the graph. Each node is assigned a label.\n",
    "\n",
    "We'll use the following names for our nodes:\n",
    "- Node with **CIA**: `\"orchestrator\"`\n",
    "- Node with **BRA**: `\"worker\"`\n",
    "- Node with **RSA**: `\"synthesizer\"`\n",
    "\n",
    "![Financial Assistant Workflow](../imgs/financial-assistant-workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangGraph Workflow and State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LangGraph** helps us manage communication between our agents efficiently by defining a `State` class that will convey information from a node to the next during execution.\n",
    "\n",
    "We keep our state simple by including only two attributes, but it's possible to include more:\n",
    "- Messages: The ongoing conversation chain\n",
    "- Analyses: Research findings from our agents\n",
    "\n",
    "We use Python's dataclasses with special annotations (`Annotated`) to define how the state attributes should be updated throughout the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Annotated\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(kw_only=True)\n",
    "class State:\n",
    "    \"\"\"Graph state for the financial analysis workflow.\"\"\"\n",
    "\n",
    "    messages: Annotated[list[BaseMessage], add_messages] = field(default_factory=list)\n",
    "    analyses: Annotated[list[str], operator.add] = field(default_factory=list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Agents in Detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Client Interface Agent (CIA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CIA serves as our system's orchestrator. It:\n",
    "- Evaluates client requests\n",
    "- Determines if requests are within scope\n",
    "- Breaks down the request into specific tasks to be conducted by the Bloomberg Research Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structured Outputs with Pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leveraging **Pydantic**, **LangChain** allows to constrain the output of a model using `.with_structured_output()`. Similarly to `.bind_tools()`, this provides the model with all the relevant information to structure its output in the desired way.\n",
    "\n",
    "We define two structured outputs:\n",
    "- ResearchTask: Defines specific research objectives\n",
    "- OrchestratorDecision: Helps the CIA answer the client's request and plan the research tasks\n",
    "\n",
    "This approach helps maintain consistency and reliability during our workflow execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchTask(BaseModel):\n",
    "    \"\"\"Task for the financial analysis workflow.\"\"\"\n",
    "\n",
    "    topic: str = Field(description=\"Topic of the research task.\")\n",
    "    description: str = Field(\n",
    "        description=\"Brief description of the task and its objectives.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class OrchestratorDecision(BaseModel):\n",
    "    \"\"\"List of research tasks for the financial analysis workflow.\"\"\"\n",
    "\n",
    "    response: str = Field(description=\"Rationale for the decision and research tasks.\")\n",
    "    in_scope: bool = Field(\n",
    "        description=\"Wether the client request is in scope for the financial analysis.\"\n",
    "    )\n",
    "    research_tasks: list[ResearchTask] | None = Field(\n",
    "        description=\"List of research tasks to be completed.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the we defined our structured output, we can instanciate our CIA model using `.with_structured_output()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIA_PROMPT = \"\"\"\n",
    "You are a Client Interface Agent (CIA) in a financial analysis system. You have multiple Research Agents with access to Bloomberg Financial News under your supervision.\n",
    "\n",
    "Given a client request, provide a concise, polite and professional response regarding the feasibility of the request and the approach that will be taken to address it.\n",
    "\n",
    "If the user's request is addressable, create a short list of highly specific research topics that the Research Agents will investigate to fulfill the client's request.\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Create the CIA model from the base model with structured output\n",
    "cia_model = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the Nodes and Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define our first graph Node. This section encompasses multiple **LangGraph** concepts at once and is worth spending some time on.\n",
    "\n",
    "1. Defining the node:\n",
    "    - To define our orchestrator node, we implement a function that receives the graph state and apply operations on it\n",
    "    - In this case, the `\"orchestrator\"` calls the CIA model with structured output on the user request.\n",
    "\n",
    "2. Defining the flow:\n",
    "    - In December, **LangGraph** released [`Command`](https://blog.langchain.dev/command-a-new-tool-for-multi-agent-architectures-in-langgraph/), a novel way of defining the graph edges  directly within the nodes.\n",
    "    - `Command` can return both state updates (`update`) and the next node (`goto`).\n",
    "    - In the following example, the `\"orchestrator\"` node updates the state messages with the CIA's response.\n",
    "    - If the user request is out of scope, it terminates the workflow by going to the `END` node.\n",
    "    - Otherwise, it goes to a dynamically generated number of `\"worker\"` nodes and provide them each with a `ResearchTask`.\n",
    "\n",
    "3. Dynamic number of nodes:\n",
    "    - Instead of returning a single string in `Command` we return a list.\n",
    "    - One worker is created for each research task defined by the CIA.\n",
    "    - Each worker will receive a different `ResearchTask` input using [`Send`](https://langchain-ai.github.io/langgraph/concepts/low_level/#send)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.constants import Send\n",
    "from langgraph.graph import END\n",
    "from langgraph.types import Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CIA orchestrator with the next node options\n",
    "def orchestrator_node(state: State) -> Command[Literal[\"worker\", END]]:\n",
    "    \"\"\"Orchestrator that generates a plan for the report.\"\"\"\n",
    "    display(Markdown(f\"**Client request received**: {state.messages[-1].content}\"))\n",
    "\n",
    "    # Message list for the CIA model\n",
    "    messages = [\n",
    "        SystemMessage(CIA_PROMPT),\n",
    "        *state.messages,\n",
    "    ]\n",
    "\n",
    "    # Invoke the CIA model\n",
    "    cia_output = cia_model.invoke(messages)\n",
    "\n",
    "    display(Markdown(f\"**CIA Response:** {cia_output.response}\"))\n",
    "\n",
    "    return Command(\n",
    "        # Update the state messages with the CIA response\n",
    "        update={\"messages\": cia_output.response},\n",
    "        # Go to the research nodes if the request is in scope, otherwise end the workflow\n",
    "        goto=[Send(\"worker\", task) for task in cia_output.research_tasks]\n",
    "        if cia_output.in_scope\n",
    "        else END,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bloomberg Research Agent (BRA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BRA is our research specialist that:\n",
    "- Receives specific research tasks from the CIA\n",
    "- Queries the Bloomberg news database\n",
    "- Synthesizes findings into concise research reports\n",
    "\n",
    "This node works identically to the RAG from the first notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, ToolMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BRA_PROMPT = \"\"\"\n",
    "You are a Research Agent in a financial analysis system. You are tasked with writing a concise research report on a specific topic provided by the Client Interface Agent (CIA) based on available documents.\n",
    "\n",
    "To do so, you have access to a Bloomberg Financial News database that you can query. You should query the vector store for documents relevant to your task and write a concise summary of the information you find.\n",
    "\n",
    "Your report should be short and informative, conveying only the most important information from the documents, to allow a Synthesis Agent to quickly generate a report for the client based on the findings of all Research Agents.\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Create the BRA model from the base model with tool binding\n",
    "bra_model = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define the worker node and the next node options\n",
    "def worker_node(task: ResearchTask) -> ...:\n",
    "    \"\"\"Research agent that can query the vector store for relevant documents.\"\"\"\n",
    "    display(Markdown(f\"**Researching task**: {task.topic}\"))\n",
    "\n",
    "    # TODO: Access the task topic and description from the research task\n",
    "    topic = ...\n",
    "    description = ...\n",
    "\n",
    "    # Create a string with the research task topic and description\n",
    "    task_str = f\"Research Task: {topic}\\n\\n Description: {description}\"\n",
    "\n",
    "    # TODO: Message list for the BRA model\n",
    "    messages = ...\n",
    "\n",
    "    # TODO: Invoke the BRA model with the messages\n",
    "    bra_output = ...\n",
    "\n",
    "    # TODO: If the BRA model made tool calls, invoke the tool\n",
    "    if bra_output.tool_calls:\n",
    "        ...\n",
    "        documents = ...\n",
    "\n",
    "        display(\n",
    "            Markdown(\n",
    "                f\"**Retrieved documents**: {[doc.metadata['Headline'] for doc in documents]}\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Combine the retrieved documents into a single string\n",
    "        documents_str = \"\\n\\n\".join(\n",
    "            [f\"{doc.metadata['Headline']}\\n\\n{doc.page_content}\\n\" for doc in documents]\n",
    "        )\n",
    "\n",
    "        # TODO: Message list with the retrieved documents for the base model\n",
    "        messages = ...\n",
    "\n",
    "        # TODO: Invoke the base model with the messages\n",
    "        bra_output = ...\n",
    "\n",
    "    # TODO: Update the state analyses with the BRA output content and go to the synthesizer node\n",
    "    # NOTE: To update `analyses` you should return a list\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Synthesis Agent (RSA)\n",
    "The RSA is our final processing layer that:\n",
    "- Collects all research findings\n",
    "- Cross-references different analyses\n",
    "- Creates a cohesive final report for the client\n",
    "\n",
    "It does not make use of tools nor structured outputs and should return an answer to the client based on the analyses in the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RSA_PROMPT = \"\"\"\n",
    "You are a Research Synthesis Agent (RSA) in a financial analysis system. You receive the reports from multiple Bloomberg Research Agents, and are tasked with synthesizing the information these reports contain into a final report for the client.\n",
    "\n",
    "The final report should be based on the information provided by the Research Agents, covering their findings in a clear and concise manner to address the client's request.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define the synthesizer node and the next node options\n",
    "def synthesizer_node(state: State) -> ...:\n",
    "    \"\"\"Synthesize full report from research analyses.\"\"\"\n",
    "    display(Markdown(f\"**Synthesizing research from {len(state.analyses)} BRAs.**\"))\n",
    "\n",
    "    # TODO: Access the research analyses from the state\n",
    "    analyses = ...\n",
    "\n",
    "    # Combine the research analyses into a single string\n",
    "    complete_analyses = \"\\n\\n---\\n\\n\".join(analyses)\n",
    "\n",
    "    # TODO: Message list for the RSA model\n",
    "    messages = ...\n",
    "\n",
    "    # TODO: Invoke the base model with the messages\n",
    "    rsa_output = ...\n",
    "\n",
    "    # TODO: Update the state messages with the RSA output content and end the workflow\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Workflow Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our nodes and communication flow are defined, we can build the graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from langgraph.graph import StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a state graph builder\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# Define the entry point\n",
    "graph_builder.set_entry_point(\"orchestrator\")\n",
    "\n",
    "# TODO: Add the nodes\n",
    "graph_builder.add_node(\"orchestrator\", orchestrator_node)\n",
    "...\n",
    "\n",
    "# The edges are defined by the commands !\n",
    "\n",
    "# Compile the workflow\n",
    "app = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize our Financial Analyst graph. Note that because the number of `\"worker\"` nodes is generated dynamically, it shows up as a single node in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our workflow is built, let's test it! Once again, we can run it with `.invoke()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"I want to invest in the technology sector. Can you please define an investment strategy?\"\n",
    "\n",
    "# Invoke the workflow with the client request\n",
    "final_state = app.invoke({\"messages\": request})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(final_state[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Tips\n",
    "\n",
    "- Keep agent roles clearly defined and specialized\n",
    "- Use structured outputs to ensure reliable communication\n",
    "- Monitor the workflow graph for potential bottlenecks\n",
    "- Adjust the number of research tasks based on query complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "You've now learned how to build a sophisticated multi-agent system using **LangGraph**! This approach allows for:\n",
    "- More complex and nuanced analysis\n",
    "- Better division of responsibilities\n",
    "- Scalable AI applications\n",
    "\n",
    "Feel free to experiment with different agent configurations and workflow patterns to suit your specific needs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
